# Explore SDM Results

## Setup

```{r}
source("setup.R")

# output dir
output_dir <- "data/output_sdm_2025-04-01/"

# list all directories in output_sdm
output_dirs <- list.dirs(output_dir, recursive = FALSE)

specs <- basename(output_dirs) %>% gsub(" ", "_", .)
names(specs) <- gsub("_", " ", specs)
```

### Load in data

```{r}
walk(output_dirs, ~load(list.files(.x, pattern = ".RData", full.names = TRUE), envir = .GlobalEnv))
```

# Visualize Results

```{r}
library(shiny)
library(patchwork)
library(DT)
# 
# # Load SDM results
# output_dir <- "data/output_sdm_2025-03-03/"
# output_dirs <- list.dirs(output_dir, recursive = FALSE)
# specs <- basename(output_dirs)

# Create UI
ui <- fluidPage(
  titlePanel("Species Distribution Model Viewer"),
  sidebarLayout(
    sidebarPanel(selectInput("species", "Select a Species:", choices = specs)),
    mainPanel(
      h3("Metadata"),
      DTOutput("meta_table"),
      h3("Model Performace"),
      h4("Tuning Results"),
      plotOutput("tuning_plot"),
      h3("Null Models"),
      p(
        "Compare empirical results to simulated. Here hoping for empirical eval metrics that are significantly better than a null model."
      ),
      tableOutput("null_table"),
      p(
        "Plots of the null model results as a histogram. Here we are looking for the empirical validation value (solid red line) to be significantly higher than the 99th quantile of the null values (dashed purple line). For reference, this plot also includes the null 95th quantile (dashed blue line) and the null mean (solid blue line)."
      ),
      plotOutput("null_plot"),
      h3("Variable Importance"),
      plotOutput("varimp_plot"),
      h3("Response Curves"),
      plotOutput("response_plot")
    )
  )
)

# Server logic
server <- function(input, output) {
  # observe({
  #   species_dir <- file.path(output_dir, input$species)
  #   rdata_files <- list.files(species_dir, pattern = "\\.RData$", full.names = TRUE)
  #
  #   walk(rdata_files, ~load(.x, envir = .GlobalEnv))
  # })
  
  # reactive RData object
  data <- reactive({
    paste0(input$species, "_SDM_output")
    
  })
  
  # metadata plot
  output$meta_table <- renderDT({
    get(data())[["metadata"]] %>% 
      filter(name != "projection") %>% 
      datatable( 
              options = list(
                scrollY = "400px",
                scrollCollapse = TRUE,
                paging = FALSE,
                dom = "frti"  # Controls which elements appear (no pagination)
              )
      )
    
    
  })
  
  # tuning plots
  output$tuning_plot <- renderPlot({
    evalplot.stats(
      e = get(data())[["all_mods"]],
      stats = c("auc.diff", "cbi.val", "or.10p"),
      color = "fc",
      x.var = "rm",
      error.bars = FALSE
      #dodge = 0.5
    )
  })
  
  # null model stats
  output$null_table <- renderTable({
    null.emp.results(get(data())[["null_mods"]])
    
  })
  
  
  # null model plots
  output$null_plot <- renderPlot({
    evalplot.nulls(
      get(data())[["null_mods"]],
      stats = c("or.10p", "auc.val", "cbi.val"),
      plot.type = "violin"
    )
    
  })
  
  # variable importance plots
  output$varimp_plot <- renderPlot({
    ggplot(get(data())[["variable_importance"]], aes(
      x = reorder(Variable, -Permutation_importance),
      y = Permutation_importance
    )) +
      geom_col() +
      geom_errorbar(aes(ymin = Permutation_importance - sd, ymax = Permutation_importance + sd),
                    width = 0.2) +
      xlab("") +
      theme(axis.text.x = element_text(
        angle = 45,
        vjust = 1,
        hjust = 1
      ))
  })
  
  # response curves
  
  # get list of variables
  vars <- reactive({
    get(data())[["variable_importance"]]$Variable
  })
  
  rc <- reactive({
    get(data())[["response_curves"]]
  })
  
  output$response_plot <- renderPlot({
    plots <- map(vars(),
                 ~ ggplot(rc(), aes(
                   x = !!sym(.x), y = !!sym(paste0("preds_", .x))
                 )) +
                   geom_line() +
                   xlab(.x) +
                   ylab("Presence Probability"))
    
    wrap_plots(plots, ncol = 3)
  })
  
}

# Run the app
shinyApp(ui = ui, server = server)

```


# Find Best Model

For each species, pull the best model of all predictor sets

```{r}
# remove Bombus for now since only one model run
specs2 <- specs[!(specs == "Bombus_spp")]


# get all model output folders
outputs <- list.files("data/", pattern = "output_sdm_*", include.dirs = TRUE, full.names = TRUE)
## keep only updated runs
outputs <- outputs[3:length(outputs)]


# Get all performance metrics in a single df
model_results <- map_df(names(specs2), function(x) {
  # get species folders
  mods <- list.dirs(outputs) %>%
    .[str_detect(., x)]
  
  
  # for each, read in model results and save in table
  stats <- map_df(mods, function(y) {
    # Create new environment to avoid cluttering global environment
    temp_env <- new.env()
    
    load(list.files(y, pattern = ".RData", full.names = TRUE), envir = temp_env)
    
    obj <- ls(temp_env)
    
    model_obj <- temp_env[[obj]]
    
    # save stats
    one <- null.emp.results(model_obj[["null_mods"]])[6, "cbi.val"]
    two <- model_obj$metadata %>% filter(name == "cbi.val.avg") %>% pull(value)
    three <- model_obj$metadata %>% filter(name == "auc.diff.avg") %>% pull(value)
    
    tibble(
      species = x,
      model = y,
      cbi_val_pvalue = one,
      cbi_val_avg = two,
      auc_diff_avg = three
    )
    
  })
  
  return(stats)
  
})

```

Filter best model for each species
```{r}
best_models <- map_df(names(specs2), function(x) {
  model_results %>%
    filter(species == x) %>%
    filter(cbi_val_pvalue <= 0.05) %>%
    filter(cbi_val_avg == max(cbi_val_avg))
})
```

